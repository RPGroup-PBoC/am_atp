{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ae39a2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049d54f9-ec1e-46ba-80b5-ae58460ed389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import time\n",
    "import time\n",
    "\n",
    "# Numpy imports:    \n",
    "import numpy as np\n",
    "\n",
    "# Pandas for csv \n",
    "import pandas as pd\n",
    "\n",
    "# for extracting filenames \n",
    "import glob\n",
    "\n",
    "#Matplotlib imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# skimage submodules we need\n",
    "import skimage.io\n",
    "\n",
    "#Scipy imports\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os\n",
    "\n",
    "import atp_hydro\n",
    "atp_hydro.pboc_style_mpl()\n",
    "# show images in viridis by default (pboc is fire?)\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "# Import seaborn for aesthetic plots \n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be36199-0475-4f8e-9480-20ec78d9f563",
   "metadata": {},
   "source": [
    "### Find Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea046429",
   "metadata": {},
   "source": [
    "Input imaging parameters to get time steps right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72da7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_int = 20 #s\n",
    "Motconc = 1 #uM, NCD Motors \n",
    "skip_int = 5 #data frames to skip \n",
    "\n",
    "# Declare where data is stored \n",
    "datapath = '/Volumes/Najma/'\n",
    "\n",
    "# Declaring folders to iterate over\n",
    "datafolders = ['ATP/', 'ADP/', 'Phosphate/']; \n",
    "datafolders = ['ATP/']; # Picking one datafolder at a time makes processing easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00528c61",
   "metadata": {},
   "source": [
    "Function to find all file paths that have folders that contain tiff files. This makes it easier to locate the subfolders that contain the tiff files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b604531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find all file paths that have folders that contain tiff files. This makes it easier to locate the subfolders that contain the tiff files.\n",
    "def find_file_paths(root_dir, file_name, result=None):\n",
    "    if result is None:\n",
    "        result = []\n",
    "\n",
    "    # Iterate over all files and directories in the current directory\n",
    "    for item in os.listdir(root_dir):\n",
    "        item_path = os.path.join(root_dir, item)\n",
    "\n",
    "        # Check if the current item is a file with the desired name\n",
    "        if os.path.isfile(item_path) and file_name in item:\n",
    "            result.append(\"/\".join(item_path.split('/')[:-1]))\n",
    "            break\n",
    "\n",
    "        # Check if the current item is a directory, then recurse into it\n",
    "        elif os.path.isdir(item_path):\n",
    "            find_file_paths(item_path, file_name, result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f066ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiff files:  17\n"
     ]
    }
   ],
   "source": [
    "tiff_folders = []; \n",
    "for folder in datafolders: \n",
    "\n",
    "    # Example usage:\n",
    "    root_directory = datapath + folder; \n",
    "\n",
    "    target_file_name = \".tif\"; \n",
    "    file_paths = find_file_paths(root_directory, target_file_name); \n",
    "\n",
    "    [tiff_folders.append(file_paths)]; \n",
    "tiff_folders = [item for sublist in tiff_folders for item in sublist]; \n",
    "\n",
    "print('Number of tiff files: ', len(tiff_folders))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8daafe",
   "metadata": {},
   "source": [
    "### Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64e6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calls automated data processing function from atp hydro packages\n",
    "\n",
    "def process_folder(datafolder):\n",
    "    #--------- Read in Files -----------#\n",
    "    # bound Images\n",
    "    included_bound = '*405*.tif'\n",
    "    bound_files = np.sort(glob.glob(datafolder+'/'+included_bound))[::skip_int]\n",
    "\n",
    "    # unbound Images\n",
    "    included_unbound = '*480*.tif'\n",
    "    unbound_files = np.sort(glob.glob(datafolder+'/'+included_unbound))[::skip_int]\n",
    "\n",
    "    # ------------------ Process file ------------------ #\n",
    "    \n",
    "    linear_params, linear_r2, exp_params, rate, exp_r2, times, ratio_hydro_uM, ratio_hydro, bound_hydro, unbound_hydro, linear_data_regime, exponential_fit_start_time = atp_hydro.analyze_hydrolysis(\n",
    "                                                            bound_files, \n",
    "                                                            unbound_files, \n",
    "                                                            frame_int, \n",
    "                                                            skip_int, \n",
    "                                                            cal_params = [67.60201128,  3.36417414,  1.06783864,  1.17289855], # to do: Try recallibration with exponent = 1. \n",
    "                                                            p0=[2000, 500, 5],\n",
    "                                                            Motconc=Motconc\n",
    "                                                            )\n",
    "\n",
    "    return linear_params, linear_r2, exp_params, rate, exp_r2, times, ratio_hydro_uM, ratio_hydro, bound_hydro, unbound_hydro, linear_data_regime, exponential_fit_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854c5fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 of 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mashok/Documents/analysis/am_atp/analysis/atp-hydro/atp_hydro/atp_hydro_packages.py:209: RuntimeWarning: invalid value encountered in power\n",
      "  return a * ((c - array) / (array - b)) ** (1/d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2 of 17\n",
      "File 3 of 17\n",
      "File 4 of 17\n",
      "File 5 of 17\n",
      "File 6 of 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mashok/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_minpack_py.py:906: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 7 of 17\n",
      "File 8 of 17\n",
      "File 9 of 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mashok/Library/Python/3.9/lib/python/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/Users/mashok/Library/Python/3.9/lib/python/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/mashok/Documents/analysis/am_atp/analysis/atp-hydro/atp_hydro/atp_hydro_packages.py:241: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - ssres/sstot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 10 of 17\n",
      "File 11 of 17\n",
      "File 12 of 17\n",
      "File 13 of 17\n",
      "File 14 of 17\n",
      "File 15 of 17\n",
      "File 16 of 17\n",
      "File 17 of 17\n"
     ]
    }
   ],
   "source": [
    "# Stores results\n",
    "linear_parameters_list = []; \n",
    "linear_r2_list = []; \n",
    "exponential_parameters_list = []; \n",
    "exponential_hydrolysis_rates_list = []; \n",
    "exp_r2_list = []; \n",
    "exponential_fit_start_time_list = []; \n",
    "linear_data_regime_list = []; \n",
    "ATP_data_list = []; \n",
    "Bound_data_list = []; \n",
    "Unbound_data_list = []; \n",
    "Ratio_list = []; \n",
    "time_list = []; \n",
    "\n",
    "for i, folder in enumerate(tiff_folders): \n",
    "    print(f\"File {i+1} of {len(tiff_folders)}\")    \n",
    "    \n",
    "    # Record the start time\n",
    "    linear_params, linear_r2, exp_params, rate, exp_r2, times, ratio_hydro_uM, ratio_hydro, bound_hydro, unbound_hydro, linear_data_regime, exponential_fit_start_time = process_folder(folder)\n",
    "\n",
    "    linear_parameters_list.append(linear_params); \n",
    "    linear_r2_list.append(linear_r2); \n",
    "    exponential_parameters_list.append(exp_params); \n",
    "    exponential_hydrolysis_rates_list.append(rate); \n",
    "    exp_r2_list.append(exp_r2);  \n",
    "    linear_data_regime_list.append(linear_data_regime); \n",
    "    exponential_fit_start_time_list.append(exponential_fit_start_time); \n",
    "    ATP_data_list.append(ratio_hydro_uM); \n",
    "    Ratio_list.append(ratio_hydro); \n",
    "    Bound_data_list.append(bound_hydro); \n",
    "    Unbound_data_list.append(unbound_hydro); \n",
    "    time_list.append(times); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6586d45",
   "metadata": {},
   "source": [
    "### Saving in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eafe71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------Collect conditions from file names ------# \n",
    "\n",
    "ATP_list = []; \n",
    "ADP_list = []; \n",
    "Phosphate_list = []; \n",
    "A81D_list = []; \n",
    "ExposureTime_405_list = []; \n",
    "ExposureTime_480_list = []; \n",
    "FrameInterval_list = []; \n",
    "\n",
    "for i, file in enumerate(tiff_folders): \n",
    "    split_file = file.split('/')\n",
    "\n",
    "    # For ATP folder\n",
    "    if split_file[3] == 'ATP': \n",
    "        ADP_list.append(0)\n",
    "        Phosphate_list.append(0)\n",
    "        ATP_list.append(int(split_file[-1].split(\"_\")[0][:-5])) \n",
    "    \n",
    "    # For ADP folder\n",
    "    elif split_file[3] == 'ADP':\n",
    "        Phosphate_list.append(0); \n",
    "        ADP_list.append(int(split_file[-1].split(\"_\")[0][:-5]))\n",
    "        ATP_list.append(int(split_file[4].split(\"_\")[-1][:-5])) \n",
    "\n",
    "    # For Phosphate folder\n",
    "    elif split_file[3] == 'Phosphate':\n",
    "        \n",
    "        ADP_list.append(0);    \n",
    "\n",
    "        ATP_conc = int(split_file[4].split('_')[-1][:-5])\n",
    "        ATP_list.append(ATP_conc)\n",
    "\n",
    "        if split_file[5].split('_')[0] == \"Nikon\":\n",
    "            P_conc = int(split_file[6].split('_')[0][:-4])\n",
    "        else: \n",
    "            P_conc = int(split_file[5].split('_')[0][:-4])\n",
    "        Phosphate_list.append(P_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63fdeddc-6036-4556-987c-8b4e7bf6555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info below taken from file names (eg: Nikon_10X_bin1_20sFrameInterval_100ms480_150ms405_50uMATP_1uMmicro_1400nM_A81D_2). Stays constant for all experiments.\n",
    "FrameInterval = 20; #seconds\n",
    "Channel480ExposureTime = 100/1e3; #seconds\n",
    "Channel405ExposureTime = 150/1e3; #seconds\n",
    "A81D_conc = 1400; #nM \n",
    "\n",
    "df_anal = pd.DataFrame({'Data Location' : tiff_folders,\n",
    "                        'ATP Concentration (uM)' : ATP_list, #convert into string\n",
    "                        'ADP Concentration (uM)' : ADP_list,\n",
    "                        'P Concentration (uM)' : Phosphate_list,\n",
    "                        'NCD Micro Motor Concentration (uM)' : [1]*len(tiff_folders), # Same motor concentrations for this set of experiments\n",
    "                        'r-squared for exponential fit' : exp_r2_list,\n",
    "                        'Tau (s)' : [params[0] for params in exponential_parameters_list],\n",
    "                        'A0 (uM)' : [params[1] for params in exponential_parameters_list],\n",
    "                        'Ainf (uM)' : [params[2] for params in exponential_parameters_list],\n",
    "                        'Exponential Fitting Start Time (seconds)' : exponential_fit_start_time_list, \n",
    "                        'Hydrolysis Rate (uM/s/motor) from Exponential Curve' : exponential_hydrolysis_rates_list,\n",
    "                        'Linear Data Regime (start and end time in seconds)' : linear_data_regime_list,\n",
    "                        'Hydrolysis Rate (uM/s/motor) from Linear Fitting (-abs(Slope)/Motconc)' : [-lparam[0]/Motconc for lparam in linear_parameters_list],\n",
    "                        'Y-intercept of Linear Curve from Linear Fitting' : [lparam[1] for lparam in linear_parameters_list],\n",
    "                        'r-squared for linear fit' : linear_r2_list,\n",
    "                        'Cal_Param [Km, Rmax, Rmin, n]' : [[67.60201128,  3.36417414,  1.06783864,  1.17289855]]*len(tiff_folders), # Same callibration for each experiment \n",
    "                        'Frame Interval (s)': [20]*len(tiff_folders), \n",
    "                        '480 Channel Exposure Time (s)': [Channel480ExposureTime]*len(tiff_folders), \n",
    "                        '405 Channel Exposure Time (s)': [Channel405ExposureTime]*len(tiff_folders), \n",
    "                        'A81D Concentration (nM)': [A81D_conc]*len(tiff_folders),\n",
    "                        'Time Array (s)': [list(time) for time in time_list], \n",
    "                        'ATP Curve (uM)':  [list(ATP) for ATP in ATP_data_list],\n",
    "                        'Bound Curve':  [list(bound_array) for bound_array in Bound_data_list],\n",
    "                        'Unbound Curve':  [list(unbound_array) for unbound_array in Unbound_data_list],\n",
    "                        'Ratio (A.U.)':  [list(ratio) for ratio in Ratio_list]\n",
    "                        })\n",
    "\n",
    "df_anal.to_csv('../../analyzed_data/atp-hydro/ATP.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
