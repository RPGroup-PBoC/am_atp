{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b1040e",
   "metadata": {},
   "source": [
    "Script to automate data preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae39a2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049d54f9-ec1e-46ba-80b5-ae58460ed389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import time\n",
    "import time\n",
    "\n",
    "# Numpy imports:    \n",
    "import numpy as np\n",
    "\n",
    "# Pandas for csv \n",
    "import pandas as pd\n",
    "\n",
    "# for extracting filenames \n",
    "import glob\n",
    "\n",
    "#Matplotlib imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# skimage submodules we need\n",
    "import skimage.io\n",
    "\n",
    "#Scipy imports\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os\n",
    "\n",
    "import atp_hydro\n",
    "atp_hydro.pboc_style_mpl()\n",
    "# show images in viridis by default (pboc is fire?)\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "# Import seaborn for aesthetic plots \n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc70a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"../../data/atp_hydro/1000uM_ATP_0_ADP_0_P/\"; # Specify data location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ad505",
   "metadata": {},
   "source": [
    "# Old Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be36199-0475-4f8e-9480-20ec78d9f563",
   "metadata": {},
   "source": [
    "### Find Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea046429",
   "metadata": {},
   "source": [
    "Input imaging parameters to get time steps right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72da7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_int = 20 #s\n",
    "Motconc = 1 #uM, NCD Motors \n",
    "skip_int = 5 #data frames to skip \n",
    "\n",
    "# Declare where data is stored \n",
    "datapath = '/Volumes/Najma/'\n",
    "\n",
    "# Declaring folders to iterate over\n",
    "datafolders = ['ATP/', 'ADP/', 'Phosphate/']; \n",
    "datafolders = ['ATP/']; # Picking one datafolder at a time makes processing easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00528c61",
   "metadata": {},
   "source": [
    "Function to find all file paths that have folders that contain tiff files. This makes it easier to locate the subfolders that contain the tiff files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b604531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find all file paths that have folders that contain tiff files. This makes it easier to locate the subfolders that contain the tiff files.\n",
    "def find_file_paths(root_dir, file_name, result=None):\n",
    "    if result is None:\n",
    "        result = []\n",
    "\n",
    "    # Iterate over all files and directories in the current directory\n",
    "    for item in os.listdir(root_dir):\n",
    "        item_path = os.path.join(root_dir, item)\n",
    "\n",
    "        # Check if the current item is a file with the desired name\n",
    "        if os.path.isfile(item_path) and file_name in item:\n",
    "            result.append(\"/\".join(item_path.split('/')[:-1]))\n",
    "            break\n",
    "\n",
    "        # Check if the current item is a directory, then recurse into it\n",
    "        elif os.path.isdir(item_path):\n",
    "            find_file_paths(item_path, file_name, result)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8daafe",
   "metadata": {},
   "source": [
    "### Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64e6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calls automated data processing function from atp hydro packages\n",
    "\n",
    "def read_images(datafolder, skip_int = 1):\n",
    "    # bound Images\n",
    "    included_bound = '*405*.tif'\n",
    "    bound_files = np.sort(glob.glob(datafolder+'/'+included_bound))[::skip_int]\n",
    "    bound_images = [skimage.io.imread(image_location) for image_location in bound_files]; \n",
    "    # unbound Images\n",
    "    included_unbound = '*480*.tif'\n",
    "    unbound_files = np.sort(glob.glob(datafolder+'/'+included_unbound))[::skip_int]\n",
    "    unbound_images = [skimage.io.imread(image_location) for image_location in unbound_files]; \n",
    "\n",
    "    return bound_images, unbound_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5919cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_dark_avg(file_path_dark):\n",
    "    \"\"\"\n",
    "    Imports a dark image.\n",
    " \n",
    "    Parameters:\n",
    "    file_path_dark (string): Data path for a dark image.\n",
    "    \n",
    "    Returns:\n",
    "    dark_avg (numpy.ndarray): Dark image as a 2D array.\n",
    "    \"\"\"\n",
    "    dark_files = np.sort(glob.glob(file_path_dark))\n",
    "    dark_ims = np.array([skimage.io.imread(image_location) for image_location in dark_files]); \n",
    "    dark_avg = np.average(dark_ims, axis=0)\n",
    "    return dark_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ce0439",
   "metadata": {},
   "source": [
    "#### Functions relating to correcting uneven illumination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2a62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(arrs):\n",
    "    \"\"\"\n",
    "    The camera has an occasional jitter, illuminating slightly different fields of view. This function finds pixels illluminated in all frames\n",
    "    \n",
    "    Parameters:\n",
    "    arrs (lsit): list of 3D numpy.ndarray's containing aster images where each array is from a different fluorescent channel.\n",
    "    \n",
    "    Returns:\n",
    "    (tuple): tuple containing the pixel coordinates for pixels illuminated in all images. The tuple has two 1D arrays, one for each image dimension.\n",
    "    \"\"\"\n",
    "    _, numRows, numCols=arrs[0].shape\n",
    "    \n",
    "    #iterate through frame numbers\n",
    "    severeIntersection=np.ones_like(arrs[0][0]);\n",
    "    \n",
    "    for fr in range(arrs[0].shape[0]): # for every timepoint\n",
    "        #iterate through channels:\n",
    "        ## Process the ATP channels first!\n",
    "        im_bins=[]\n",
    "        for arr in arrs[:2]: #exclude the motor channel!\n",
    "            im_bin = (arr[fr,:,:] > threshold_otsu(arr[fr,:,:])).astype(np.uint8)\n",
    "            im_bins.append(im_bin)\n",
    "        intersectionBinImg=np.multiply(*im_bins) # This is defined for each frame/timepoint; it is the intersection between both channels' masks\n",
    "        severeIntersection=np.multiply(severeIntersection, intersectionBinImg) # This accumulates the most severe intersection possible such that after iteration over all frames, all pixels not = 0 are visible/illuminated in every frame and every channel\n",
    "\n",
    "    return np.where(severeIntersection.astype(int)) #returns where =1 (or True)\n",
    "\n",
    "def flatten_image_with_coordinates(image): \n",
    "    \"\"\"\" Given an image in numpy array format, this function returns the flattened image and corresponding 2D coordinates of the pixels.\"\"\"\n",
    "    # Extract coordinates and values of each pixel into a flattened array\n",
    "    vals = image.flatten(); \n",
    "    coord = np.unravel_index(np.arange(vals.size), image.shape); \n",
    "\n",
    "    return vals, coord\n",
    "\n",
    "def fit_bivariate_quadratic_anyShape(image):\n",
    "    \"\"\"\n",
    "    Fits a bivariate quadratic polynomial to the intensity values of a grayscale image.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy.ndarray): First image in experiment.\n",
    "    \n",
    "    Returns:\n",
    "    coefficients (numpy.ndarray): Coefficients of the fitted polynomial [a00, a10, a01, a20, a11, a02].\n",
    "    \"\"\"\n",
    "    # Extract coordinates and values of each pixel into a flattened array\n",
    "    vals, coord = flatten_image_with_coordinates(image); \n",
    "\n",
    "    # Flatten the matrices for the least squares fitting\n",
    "    I_flat = coord[0]   # Y location of pixel in image\n",
    "    J_flat = coord[1]   # X location of pixel in image\n",
    "    Z_flat = vals       # Pixel Intesity at (X, Y)\n",
    "\n",
    "    # Create the design matrix for the polynomial terms\n",
    "    A = np.vstack([I_flat**2, J_flat**2, I_flat*J_flat, I_flat, J_flat, np.ones_like(I_flat)]).T\n",
    "\n",
    "    # Solve for the coefficients using least squares\n",
    "    coefficients, _, _, _ = np.linalg.lstsq(A, Z_flat, rcond=None)\n",
    "\n",
    "    return coefficients, I_flat, J_flat\n",
    "\n",
    "def evaluateBivPoly_anyShape(image):\n",
    "    \"\"\" Given coordinates, this function returns the best-fit bivariate polynomial for image. \"\"\"\n",
    "    coefficients, I, J = fit_bivariate_quadratic_anyShape(image);\n",
    "    \n",
    "    Z_fitted = (coefficients[0] * I**2 + coefficients[1] * J**2 +\n",
    "            coefficients[2] * I * J + coefficients[3] * I +\n",
    "            coefficients[4] * J + coefficients[5])\n",
    "    return Z_fitted\n",
    "\n",
    "\n",
    "def norm_unev(arrs_sub):\n",
    "    \"\"\"\n",
    "    Corrects uneven illumination by fitting an image to a bivariate polynomial, normalizing the polynomial, and dividing an array of images by this normalized matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    arrs_sub (list): Dark image subtracted list of image arrays.\n",
    "    mask_coords (length 2 tuple): illumination mask coordinates (for one image)\n",
    "    allmask_coords (slice): slice containing all the illumination coordinates with an extra dimension to account for all timepoints\n",
    "    \n",
    "    Returns:\n",
    "    arr_ev (list): list of image arrays after the evening process.\n",
    "    \"\"\"\n",
    "    #norm_mats = []\n",
    "    arrs_ev = []\n",
    "    \n",
    "    # Extract coordinates and values of each pixel into a flattened array\n",
    "    _, mask_coords = flatten_image_with_coordinates(arrs_sub[0][0]); \n",
    "    allmask_coords = np.s_[:, mask_coords[0], mask_coords[1]]; \n",
    "    \n",
    "    for arr in arrs_sub: # Iterate over channels\n",
    "        print(\"time before polynomial fitting\", time.time()); \n",
    "        #compute the bivariate filter\n",
    "        biv_filt = np.zeros_like(arr[0]) \n",
    "        biv_filt[mask_coords] = evaluateBivPoly_anyShape(arr[0, :, :])\n",
    "        #norm_mats.append(norm_mat)\n",
    "        print(\"time after polynomial fitting\", time.time());\n",
    "        #scale the normalization matrix such that the average value after multiplication is the same as the bs image\n",
    "        scalar = np.mean(arr[0][mask_coords])/np.mean(arr[0][mask_coords]/biv_filt[mask_coords])\n",
    "        norm_mat = scalar/biv_filt\n",
    "        print(\"time after normalising matrix\", time.time());\n",
    "        arrs_ev_temp = np.zeros_like(arr)\n",
    "        arrs_ev_temp[allmask_coords]=arr[allmask_coords]*norm_mat[mask_coords]\n",
    "        print(\"time after masking\", time.time());\n",
    "        \n",
    "        arrs_ev.append(arrs_ev_temp)\n",
    "        print(\"time after appending\", time.time());\n",
    "        \n",
    "    return arrs_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5539ca",
   "metadata": {},
   "source": [
    "#### Functions relating to ratio calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae46247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_calparams(file_path_cal):\n",
    "    \"\"\"\n",
    "    Imports ATP calibration parameters as a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path_cal (string): Data path to a text file with fitting parameters for ATP calibration\n",
    "    \n",
    "    Returns:\n",
    "    cal_params (pd.DataFrame): DataFrame with ATP calibration fitting parameters.\n",
    "    \"\"\"\n",
    "        \n",
    "    #read the DataFrame\n",
    "    #cal_params = pd.read_csv(cal_file_path+cal_file_folder+cal_file_name)\\\n",
    "    cal_params = pd.read_csv(file_path_cal)\n",
    "\n",
    "    #add hill=1 if no hill specified\n",
    "    if len(cal_params)==3:\n",
    "        cal_params.loc[-1] = [3, 'nhill', 1, 0]\n",
    "    \n",
    "    #reindex\n",
    "    cal_params = cal_params.set_index('Param')\n",
    "    \n",
    "    #drop the unnamed colum (from index of text file)\n",
    "    cal_params = cal_params.drop(columns='Unnamed: 0')\n",
    "    \n",
    "    return cal_params\n",
    "\n",
    "def replace_out_of_range_values(arr, min_value, max_value):\n",
    "    \"\"\"\n",
    "    Crop the intensities of an array to be withing a defined range.\n",
    "    \n",
    "    Parameters:\n",
    "    arr (numpy.ndarray): images array.\n",
    "    min_value (float): minimum value below which all other values are set to the minimum\n",
    "    max_value (float): maximum value above which all other values are set to the maximum\n",
    "    \n",
    "    Returns:\n",
    "    arr_copy (numpy.ndarray): image array cropped to the set intensity range.\n",
    "    \"\"\"\n",
    "    arr_copy = np.copy(arr)\n",
    "    mask_min = arr < min_value\n",
    "    mask_max = arr > max_value\n",
    "    arr_copy[mask_min] = min_value\n",
    "    arr_copy[mask_max] = max_value\n",
    "    return arr_copy\n",
    "\n",
    "def ATP_conc_to_ratio(array, Km, Rmax, Rmin, nhill):\n",
    "    \"\"\"Given a set of concentrations, returns ratio values based on provided Hill equation coefficients\"\"\"\n",
    "    return (Rmax-Rmin)*((array/Km)**nhill/(1 + (array/Km))**nhill) + Rmin\n",
    "\n",
    "def ATP_ratio_to_conc(array, Km, Rmax, Rmin, nhill):\n",
    "    \"\"\"Given a set of ratios, returns concentration values based on provided Hill equation coefficients\"\"\"\n",
    "    return Km * ((Rmin - array) / (array - Rmax)) ** (1/nhill)\n",
    "\n",
    "def infer_concs(ratios, exp_params, cal_params, allmask_coords, shape):\n",
    "    \"\"\"\n",
    "    Convert ratios images to concentrations. (outputs an image array)\n",
    "    \n",
    "    Parameters:\n",
    "    ratios (numpy.ndarray): ratio array of shape (# timepoints, #of ratio values to convert).\n",
    "    exp_params (dictionary): dictonary of experimental parameters\n",
    "    cal_params (dictionary): maximum value above which all other values are set to the maximum\n",
    "    allmask_coords (slice): coordinates for multiple timepoints \n",
    "    shape (tuple): shape of image array\n",
    "    \n",
    "    Returns:\n",
    "    ratios_conc_ims (numpy.ndarray): image array in concentration units.\n",
    "    \"\"\"\n",
    "    #Find the ratio value for the inital ATP conc value based on calibration curve equation\n",
    "\n",
    "    print(\"Find the ratio value for the inital ATP conc value based on calibration curve equation\")\n",
    "    RinitATP = ATP_conc_to_ratio(exp_params['ATP_conc'], \n",
    "                                 cal_params.loc['Km']['Value'], \n",
    "                                 cal_params.loc['Rmax']['Value'],\n",
    "                                 cal_params.loc['Rmin']['Value'], \n",
    "                                 cal_params.loc['nhill']['Value'])\n",
    "    #Crop the ratios to within range\n",
    "    print(\"Crop the ratios to within range\")\n",
    "    ratios_inrange = replace_out_of_range_values(ratios, \n",
    "                                                 cal_params.loc['Rmin']['Value'], \n",
    "                                                 RinitATP)\n",
    "    #convert ratios to concentrations\n",
    "    print(\"convert ratios to concentrations\")\n",
    "    ratios_conc = ATP_ratio_to_conc(ratios_inrange, cal_params.loc['Km']['Value'], \n",
    "                                     cal_params.loc['Rmax']['Value'],\n",
    "                                     cal_params.loc['Rmin']['Value'], \n",
    "                                     cal_params.loc['nhill']['Value'])\n",
    "    #put ratios array into an imag\n",
    "    print(\"put ratios array into an imag\")\n",
    "    ratios_conc_ims = np.zeros(shape)\n",
    "    ratios_conc_ims[allmask_coords] = ratios_conc\n",
    "    \n",
    "    return ratios_conc_ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc78eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Value  Uncertainty\n",
      "Param                        \n",
      "Km     70.232953           10\n",
      "Rmax    3.718097           10\n",
      "Rmin    1.036695           10\n",
      "nhill   1.000000            0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'even_bound_bs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(cal_params)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate ratios\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m ratios_array \u001b[38;5;241m=\u001b[39m \u001b[43meven_bound_bs\u001b[49m\u001b[38;5;241m/\u001b[39meven_unbound_bs; \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Convert ratios to atp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m atp0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m; \u001b[38;5;66;03m#in uM. TODO: Hardcoded for this example but needs to be generalised.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'even_bound_bs' is not defined"
     ]
    }
   ],
   "source": [
    "cal_file_path = '../../analyzed_data/atp_cal/'\n",
    "cal_file_folder = '2023-12-16_A81D_Cal/'\n",
    "cal_file_name = 'df_fit_example'\n",
    "cal_dir = cal_file_path+cal_file_folder+cal_file_name; \n",
    "\n",
    "cal_params = grab_calparams(cal_dir); \n",
    "print(cal_params)\n",
    "\n",
    "# Calculate ratios\n",
    "ratios_array = even_bound_bs/even_unbound_bs; \n",
    "\n",
    "# Convert ratios to atp\n",
    "atp0 = 1000; #in uM. TODO: Hardcoded for this example but needs to be generalised.\n",
    "exp_params = {\n",
    "    \"ATP_conc\": atp0,\n",
    "}; \n",
    "\n",
    "# Extract coordinates and values of each pixel into a flattened array\n",
    "_, mask_coords = flatten_image_with_coordinates(ratios_array[0]); \n",
    "allmask_coords = np.s_[:, mask_coords[0], mask_coords[1]]; \n",
    "\n",
    "infer_concs(ratios_array, exp_params, cal_params, allmask_coords, ratios_array[0].shape); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e4738a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(datafolder, skip_int = 1):\n",
    "    now = time.time()\n",
    "    print(\"time\", now)\n",
    "    #--------- Read Images -----------#\n",
    "    bound_images, unbound_images = read_images(datafolder, skip_int = 1); \n",
    "    \n",
    "    #--------- Read Dark Files -----------#\n",
    "    dark_avg = grab_dark_avg('../../data/dark_ims/2021-01-13_nocamera_dark_1/*Pos*/*tif*');\n",
    "\n",
    "    #--------- Subtract Dark Image Background from Experiment Images -----------#\n",
    "    bound_bs = bound_images - dark_avg; \n",
    "    unbound_bs = unbound_images - dark_avg; \n",
    "    print(\"normalisation starting in \", now - time.time(), \" s\"); \n",
    "\n",
    "    #--------- Camera has Uneven Illumincation. Correct this Unevent Illumination in Background Subtracted Images -----------#\n",
    "    [even_bound_bs, even_unbound_bs] = norm_unev([bound_bs, unbound_bs]); \n",
    "    print(\"normalisation finished in \", now - time.time(), \" s\"); \n",
    "    \n",
    "    #--------- Calculate Ratios -----------#\n",
    "    ratios_array = even_bound_bs/even_unbound_bs; \n",
    "    #--------- Convert Ratio to ATP -----------#\n",
    "    cal_file_path = '../../analyzed_data/atp_cal/'\n",
    "    cal_file_folder = '2023-12-16_A81D_Cal/'\n",
    "    cal_file_name = 'df_fit_example'\n",
    "    cal_dir = cal_file_path+cal_file_folder+cal_file_name; \n",
    "\n",
    "    cal_params = grab_calparams(cal_dir); \n",
    "\n",
    "    # Convert ratios to atp\n",
    "    atp0 = 1000; #in uM. TODO: Hardcoded for this example but needs to be generalised.\n",
    "    exp_params = {\n",
    "        \"ATP_conc\": atp0,\n",
    "    }; \n",
    "\n",
    "    # Extract coordinates and values of each pixel into a flattened array\n",
    "    _, mask_coords = flatten_image_with_coordinates(ratios_array[0]); \n",
    "    allmask_coords = np.s_[:, mask_coords[0], mask_coords[1]]; \n",
    "\n",
    "    # ratios_conc_ims = infer_concs(ratios_array, exp_params, cal_params, allmask_coords, ratios_array[0].shape); \n",
    "\n",
    "    return bound_images, unbound_images, bound_bs, unbound_bs, even_bound_bs, even_unbound_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6efa6129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 1733269380.476502\n",
      "normalisation starting in  -12.056621074676514  s\n",
      "time before polynomial fitting 1733269392.634846\n",
      "time after polynomial fitting 1733269392.9929311\n",
      "time after normalising matrix 1733269393.055692\n",
      "time after masking 1733269438.610871\n",
      "time after appending 1733269438.6138492\n",
      "time before polynomial fitting 1733269438.613874\n",
      "time after polynomial fitting 1733269438.9890308\n",
      "time after normalising matrix 1733269439.078881\n",
      "time after masking 1733269498.3254342\n",
      "time after appending 1733269498.327669\n",
      "normalisation finished in  -117.86560702323914  s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bound_images, unbound_images, bound_bs, unbound_bs, even_bound_bs, even_unbound_bs \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_location\u001b[49m\u001b[43m)\u001b[49m; \n",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m, in \u001b[0;36mprocess_folder\u001b[0;34m(datafolder, skip_int)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalisation finished in \u001b[39m\u001b[38;5;124m\"\u001b[39m, now \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m); \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#--------- Calculate Ratios -----------#\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m ratios_array \u001b[38;5;241m=\u001b[39m \u001b[43meven_bound_bs\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43meven_unbound_bs\u001b[49m; \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#--------- Convert Ratio to ATP -----------#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m cal_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../analyzed_data/atp_cal/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bound_images, unbound_images, bound_bs, unbound_bs, even_bound_bs, even_unbound_bs = process_folder(data_location); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_file_path = '../../analyzed_data/atp_cal/'\n",
    "cal_file_folder = '2023-12-16_A81D_Cal/'\n",
    "cal_file_name = 'df_fit_example'\n",
    "cal_dir = cal_file_path+cal_file_folder+cal_file_name; \n",
    "\n",
    "cal_params = grab_calparams(cal_dir); \n",
    "print(cal_params)\n",
    "\n",
    "# Calculate ratios\n",
    "ratios_array = even_bound_bs/even_unbound_bs; \n",
    "\n",
    "# Convert ratios to atp\n",
    "atp0 = 1000; #in uM. TODO: Hardcoded for this example but needs to be generalised.\n",
    "exp_params = {\n",
    "    \"ATP_conc\": atp0,\n",
    "}; \n",
    "\n",
    "# Extract coordinates and values of each pixel into a flattened array\n",
    "_, mask_coords = flatten_image_with_coordinates(ratios_array[0]); \n",
    "allmask_coords = np.s_[:, mask_coords[0], mask_coords[1]]; \n",
    "\n",
    "infer_concs(ratios_array, exp_params, cal_params, allmask_coords, ratios_array[0].shape); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e75c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6878ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(even_bound_bs[0]); \n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(even_unbound_bs[0]); \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores results\n",
    "linear_parameters_list = []; \n",
    "linear_r2_list = []; \n",
    "exponential_parameters_list = []; \n",
    "exponential_hydrolysis_rates_list = []; \n",
    "exp_r2_list = []; \n",
    "exponential_fit_start_time_list = []; \n",
    "linear_data_regime_list = []; \n",
    "ATP_data_list = []; \n",
    "ATP_std_data_list = []; \n",
    "Bound_data_list = []; \n",
    "Unbound_data_list = []; \n",
    "Ratio_list = []; \n",
    "Ratio_std_list = []; \n",
    "time_list = []; \n",
    "\n",
    "for i, folder in enumerate(tiff_folders): \n",
    "    print(f\"File {i+1} of {len(tiff_folders)}\")    \n",
    "    \n",
    "    # Record the start time\n",
    "    linear_params, linear_r2, exp_params, rate, exp_r2, times, ratio_hydro_uM, atp_std, ratio_hydro, ratio_hydro_std, bound_hydro, unbound_hydro, linear_data_regime, exponential_fit_start_time = process_folder(folder)\n",
    "\n",
    "    linear_parameters_list.append(linear_params); \n",
    "    linear_r2_list.append(linear_r2); \n",
    "    exponential_parameters_list.append(exp_params); \n",
    "    exponential_hydrolysis_rates_list.append(rate); \n",
    "    exp_r2_list.append(exp_r2);  \n",
    "    linear_data_regime_list.append(linear_data_regime); \n",
    "    exponential_fit_start_time_list.append(exponential_fit_start_time); \n",
    "    ATP_data_list.append(ratio_hydro_uM); \n",
    "    ATP_std_data_list.append(atp_std); \n",
    "    Ratio_list.append(ratio_hydro); \n",
    "    Ratio_std_list.append(ratio_hydro_std); \n",
    "    Bound_data_list.append(bound_hydro); \n",
    "    Unbound_data_list.append(unbound_hydro); \n",
    "    time_list.append(times); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6586d45",
   "metadata": {},
   "source": [
    "### Saving in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------Collect conditions from file names ------# \n",
    "\n",
    "ATP_list = []; \n",
    "ADP_list = []; \n",
    "Phosphate_list = []; \n",
    "A81D_list = []; \n",
    "ExposureTime_405_list = []; \n",
    "ExposureTime_480_list = []; \n",
    "FrameInterval_list = []; \n",
    "\n",
    "for i, file in enumerate(tiff_folders): \n",
    "    split_file = file.split('/')\n",
    "\n",
    "    # For ATP folder\n",
    "    if split_file[3] == 'ATP': \n",
    "        ADP_list.append(0)\n",
    "        Phosphate_list.append(0)\n",
    "        ATP_list.append(int(split_file[-1].split(\"_\")[0][:-5])) \n",
    "    \n",
    "    # For ADP folder\n",
    "    elif split_file[3] == 'ADP':\n",
    "        Phosphate_list.append(0); \n",
    "        ADP_list.append(int(split_file[-1].split(\"_\")[0][:-5]))\n",
    "        ATP_list.append(int(split_file[4].split(\"_\")[-1][:-5])) \n",
    "\n",
    "    # For Phosphate folder\n",
    "    elif split_file[3] == 'Phosphate':\n",
    "        \n",
    "        ADP_list.append(0);    \n",
    "\n",
    "        ATP_conc = int(split_file[4].split('_')[-1][:-5])\n",
    "        ATP_list.append(ATP_conc)\n",
    "\n",
    "        if split_file[5].split('_')[0] == \"Nikon\":\n",
    "            P_conc = int(split_file[6].split('_')[0][:-4])\n",
    "        else: \n",
    "            P_conc = int(split_file[5].split('_')[0][:-4])\n",
    "        Phosphate_list.append(P_conc)\n",
    "\n",
    "print(ATP_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac635a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ATP_std_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdeddc-6036-4556-987c-8b4e7bf6555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info below taken from file names (eg: Nikon_10X_bin1_20sFrameInterval_100ms480_150ms405_50uMATP_1uMmicro_1400nM_A81D_2). Stays constant for all experiments.\n",
    "FrameInterval = 20; #seconds\n",
    "Channel480ExposureTime = 100/1e3; #seconds\n",
    "Channel405ExposureTime = 150/1e3; #seconds\n",
    "A81D_conc = 1400; #nM \n",
    "\n",
    "df_anal = pd.DataFrame({'Data Location' : tiff_folders,\n",
    "                        'ATP Concentration (uM)' : ATP_list, #convert into string\n",
    "                        'ADP Concentration (uM)' : ADP_list,\n",
    "                        'P Concentration (uM)' : Phosphate_list,\n",
    "                        'NCD Micro Motor Concentration (uM)' : [1]*len(tiff_folders), # Same motor concentrations for this set of experiments\n",
    "                        'r-squared for exponential fit' : exp_r2_list,\n",
    "                        'Tau (s)' : [params[0] for params in exponential_parameters_list],\n",
    "                        'A0 (uM)' : [params[1] for params in exponential_parameters_list],\n",
    "                        'Ainf (uM)' : [params[2] for params in exponential_parameters_list],\n",
    "                        'Exponential Fitting Start Time (seconds)' : exponential_fit_start_time_list, \n",
    "                        'Hydrolysis Rate (uM/s/motor) from Exponential Curve' : exponential_hydrolysis_rates_list,\n",
    "                        'Linear Data Regime (start and end time in seconds)' : linear_data_regime_list,\n",
    "                        'Hydrolysis Rate (uM/s/motor) from Linear Fitting (-abs(Slope)/Motconc)' : [-lparam[0]/Motconc for lparam in linear_parameters_list],\n",
    "                        'Y-intercept of Linear Curve from Linear Fitting' : [lparam[1] for lparam in linear_parameters_list],\n",
    "                        'r-squared for linear fit' : linear_r2_list,\n",
    "                        'Cal_Param [Km, Rmax, Rmin, n]' : [[67.60201128,  3.36417414,  1.06783864,  1.17289855]]*len(tiff_folders), # Same callibration for each experiment \n",
    "                        'Frame Interval (s)': [20]*len(tiff_folders), \n",
    "                        '480 Channel Exposure Time (s)': [Channel480ExposureTime]*len(tiff_folders), \n",
    "                        '405 Channel Exposure Time (s)': [Channel405ExposureTime]*len(tiff_folders), \n",
    "                        'A81D Concentration (nM)': [A81D_conc]*len(tiff_folders),\n",
    "                        'Time Array (s)': [list(time) for time in time_list], \n",
    "                        'ATP Curve (uM)':  [list(ATP) for ATP in ATP_data_list],\n",
    "                        'ATP Curve Std (uM)':  [list(ATP_std) for ATP_std in ATP_std_data_list],\n",
    "                        'Bound Curve':  [list(bound_array) for bound_array in Bound_data_list],\n",
    "                        'Unbound Curve':  [list(unbound_array) for unbound_array in Unbound_data_list],\n",
    "                        'Ratio (A.U.)':  [list(ratio) for ratio in Ratio_list],\n",
    "                        'Standard Deviation in Ratio (A.U.)':  [list(ratio_std) for ratio_std in Ratio_std_list]\n",
    "                        })\n",
    "\n",
    "df_anal.to_csv('../../analyzed_data/atp-hydro/ATP_withstd.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
